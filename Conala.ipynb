{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Entry Point [tensor2tensor.envs.tic_tac_toe_env:TicTacToeEnv] registered with id [T2TEnv-TicTacToeEnv-v0]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "tfe.enable_eager_execution()\n",
    "Modes = tf.estimator.ModeKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensor2tensor.data_generators import semantic_search\n",
    "search_problem = semantic_search.SemanticSearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Skip this if already generated data\"\"\"\n",
    "search_problem.generate_data(data_dir='/tf/t2t_data', tmp_dir='/tf/datagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PARAMS = {}\n",
    "PARAMS['T2T_Problem'] = 'semantic_search'\n",
    "PARAMS['T2T_Model'] = 'transformer'\n",
    "PARAMS['T2T_HPARAMS'] = 'transformer_base_single_gpu'\n",
    "PARAMS['train_steps'] = 10000000\n",
    "PARAMS['eval_steps'] = 1000\n",
    "PARAMS['keep_checkpoint_max'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment, create_hparams\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import models, problems\n",
    "\n",
    "hparams = create_hparams(PARAMS['T2T_HPARAMS'])\n",
    "\n",
    "FLAGS = tf.flags\n",
    "FLAGS.problems = PARAMS['T2T_Problem']\n",
    "FLAGS.problem = PARAMS['T2T_Problem']\n",
    "FLAGS.model = PARAMS['T2T_Model']\n",
    "FLAGS.schedule = \"train_and_evaluate\"\n",
    "\n",
    "\"\"\"Changing up warmup steps\"\"\"\n",
    "hparams.batch_size = 1024\n",
    "hparams.learning_rate_warmup_steps = 400\n",
    "hparams.learning_rate = .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PARAMS['TMP_DIR'] = '/tf/datagen/'\n",
    "PARAMS['DATA_DIR'] = '/tf/t2t_data'\n",
    "PARAMS['TRAIN_DIR'] = '/tf/t2t_train/intent_to_code/conala/' \n",
    "PARAMS['OUTPUT_DIR'] = 'tf/t2t_train/semantic_search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tf/tensor2tensor/utils/trainer_lib.py:240: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n"
     ]
    }
   ],
   "source": [
    "RUN_CONFIG = create_run_config(hparams, model_dir=PARAMS['TRAIN_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_fn = create_experiment(\n",
    "        run_config=RUN_CONFIG,\n",
    "        hparams=hparams,\n",
    "        model_name=PARAMS['T2T_Model'],\n",
    "        problem_name=PARAMS['T2T_Problem'],\n",
    "        data_dir=PARAMS['DATA_DIR'],\n",
    "        train_steps=PARAMS['train_steps'],\n",
    "        eval_steps=PARAMS['eval_steps']\n",
    "    )\n",
    "exp_fn.train_and_evaluate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/t2t_train/intent_to_code/conala/model.ckpt-51000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Getting latest checkpoint\"\"\"\n",
    "ckpt_path = tf.train.latest_checkpoint(PARAMS['TRAIN_DIR'])\n",
    "ckpt_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translate_model = registry.model(PARAMS['T2T_Model'])(hparams, Modes.EVAL)\n",
    "\n",
    "encoders = problems.problem(PARAMS['T2T_Problem']).feature_encoders(PARAMS['DATA_DIR'])\n",
    "\n",
    "def encode(input_str, output_str=None):\n",
    "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "    inputs = encoders[\"inputs\"].encode(input_str) + [1]  # add EOS id\n",
    "    batch_inputs = tf.reshape(inputs, [1, -1, 1])  # Make it 3D.\n",
    "    return {\"inputs\": batch_inputs}\n",
    "\n",
    "def decode(integers):\n",
    "    \"\"\"List of ints to str\"\"\"\n",
    "    integers = list(np.squeeze(integers))\n",
    "    if 1 in integers:\n",
    "        integers = integers[:integers.index(1)]\n",
    "    return encoders[\"inputs\"].decode(np.squeeze(integers))\n",
    "\n",
    "# Restore and translate!\n",
    "def translate(inputs):\n",
    "    encoded_inputs = encode(inputs)\n",
    "    with tfe.restore_variables_on_create(tf.train.latest_checkpoint(PARAMS['TRAIN_DIR'])):\n",
    "        model_output = translate_model.infer(encoded_inputs, \n",
    "                                             beam_size=4,\n",
    "                                             alpha=0.6)[\"outputs\"]\n",
    "        return decode(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>intent_tokens</th>\n",
       "      <th>question_id</th>\n",
       "      <th>rewritten_intent</th>\n",
       "      <th>slot_map</th>\n",
       "      <th>snippet</th>\n",
       "      <th>snippet_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I send a signal from a python program?</td>\n",
       "      <td>[send, a, signal, `, signal.SIGUSR1, `, to, th...</td>\n",
       "      <td>15080500</td>\n",
       "      <td>send a signal `signal.SIGUSR1` to the current ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>os.kill(os.getpid(), signal.SIGUSR1)</td>\n",
       "      <td>[os, ., kill, (, os, ., getpid, (, ), ,, signa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decode Hex String in Python 3</td>\n",
       "      <td>[decode, a, hex, string, '4a4b4c, ', to, UTF-8...</td>\n",
       "      <td>3283984</td>\n",
       "      <td>decode a hex string '4a4b4c' to UTF-8.</td>\n",
       "      <td>{}</td>\n",
       "      <td>bytes.fromhex('4a4b4c').decode('utf-8')</td>\n",
       "      <td>[bytes, ., fromhex, (, '4a4b4c', ), ., decode,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>check if all elements in a list are identical</td>\n",
       "      <td>[check, if, all, elements, in, list, `, myList...</td>\n",
       "      <td>3844801</td>\n",
       "      <td>check if all elements in list `myList` are ide...</td>\n",
       "      <td>{}</td>\n",
       "      <td>all(x == myList[0] for x in myList)</td>\n",
       "      <td>[all, (, x, ==, myList, [, 0, ], for, x, in, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Format string dynamically</td>\n",
       "      <td>[format, number, of, spaces, between, strings,...</td>\n",
       "      <td>4302166</td>\n",
       "      <td>format number of spaces between strings `Pytho...</td>\n",
       "      <td>{}</td>\n",
       "      <td>print('%*s : %*s' % (20, 'Python', 20, 'Very G...</td>\n",
       "      <td>[print, (, '%*s#SPACE#:#SPACE#%*s', %, (, 20, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to convert a string from CP-1251 to UTF-8?</td>\n",
       "      <td>[How, to, convert, a, string, from, CP-1251, t...</td>\n",
       "      <td>7555335</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d.decode('cp1251').encode('utf8')</td>\n",
       "      <td>[d, ., decode, (, 'cp1251', ), ., encode, (, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           intent  \\\n",
       "0  How can I send a signal from a python program?   \n",
       "1                   Decode Hex String in Python 3   \n",
       "2   check if all elements in a list are identical   \n",
       "3                       Format string dynamically   \n",
       "4  How to convert a string from CP-1251 to UTF-8?   \n",
       "\n",
       "                                       intent_tokens  question_id  \\\n",
       "0  [send, a, signal, `, signal.SIGUSR1, `, to, th...     15080500   \n",
       "1  [decode, a, hex, string, '4a4b4c, ', to, UTF-8...      3283984   \n",
       "2  [check, if, all, elements, in, list, `, myList...      3844801   \n",
       "3  [format, number, of, spaces, between, strings,...      4302166   \n",
       "4  [How, to, convert, a, string, from, CP-1251, t...      7555335   \n",
       "\n",
       "                                    rewritten_intent slot_map  \\\n",
       "0  send a signal `signal.SIGUSR1` to the current ...       {}   \n",
       "1             decode a hex string '4a4b4c' to UTF-8.       {}   \n",
       "2  check if all elements in list `myList` are ide...       {}   \n",
       "3  format number of spaces between strings `Pytho...       {}   \n",
       "4                                               None      NaN   \n",
       "\n",
       "                                             snippet  \\\n",
       "0               os.kill(os.getpid(), signal.SIGUSR1)   \n",
       "1            bytes.fromhex('4a4b4c').decode('utf-8')   \n",
       "2                all(x == myList[0] for x in myList)   \n",
       "3  print('%*s : %*s' % (20, 'Python', 20, 'Very G...   \n",
       "4                  d.decode('cp1251').encode('utf8')   \n",
       "\n",
       "                                      snippet_tokens  \n",
       "0  [os, ., kill, (, os, ., getpid, (, ), ,, signa...  \n",
       "1  [bytes, ., fromhex, (, '4a4b4c', ), ., decode,...  \n",
       "2  [all, (, x, ==, myList, [, 0, ], for, x, in, m...  \n",
       "3  [print, (, '%*s#SPACE#:#SPACE#%*s', %, (, 20, ...  \n",
       "4  [d, ., decode, (, 'cp1251', ), ., encode, (, '...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conala_df = pd.read_json(\"/tf/datagen/conala-test.json.prod\")\n",
    "conala_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode a hex string '4a4b4c' to UTF-8.\n",
      "bytes.fromhex('4a4b4c').decode('utf-8')\n"
     ]
    }
   ],
   "source": [
    "intent, code = conala_df.iloc[1].rewritten_intent, conala_df.iloc[1].snippet\n",
    "print(intent)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result = []\n",
    "for row in conala_df.itertuples():\n",
    "    intent = row.rewritten_intent if row.rewritten_intent else row.intent\n",
    "    code = translate(intent)\n",
    "    test_result.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Write predicted translation to file\"\"\"\n",
    "with open('/tf/datagen/translation.txt', 'w+') as f:\n",
    "    for l in test_result:\n",
    "        f.write(l+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Write intent to file so we can use test_conala.sh to decode\"\"\"\n",
    "\n",
    "with open('/tf/datagen/test_intent.txt', 'w+') as f:\n",
    "    for row in conala_df.itertuples():\n",
    "        intent = row.rewritten_intent if row.rewritten_intent else row.intent\n",
    "        f.write( intent + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
