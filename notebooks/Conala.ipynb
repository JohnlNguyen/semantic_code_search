{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ast\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import astor\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from general_utils import apply_parallel, flattenlist\n",
    "from lang_model_utils import tokenize_docstring, tokenize_code\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "EN = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data can be pulled from\n",
    "gs://conala/conala-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>question_id</th>\n",
       "      <th>rewritten_intent</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to convert a list of multiple integers int...</td>\n",
       "      <td>41067960</td>\n",
       "      <td>Concatenate elements of a list 'x' of multiple...</td>\n",
       "      <td>sum(d * 10 ** i for i, d in enumerate(x[::-1]))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to convert a list of multiple integers int...</td>\n",
       "      <td>41067960</td>\n",
       "      <td>convert a list of integers into a single integer</td>\n",
       "      <td>r = int(''.join(map(str, x)))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to convert a datetime string back to datet...</td>\n",
       "      <td>4170655</td>\n",
       "      <td>convert a DateTime string back to a DateTime o...</td>\n",
       "      <td>datetime.strptime('2010-11-13 10:33:54.227806'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Averaging the values in a dictionary based on ...</td>\n",
       "      <td>29565452</td>\n",
       "      <td>get the average of a list values for each key ...</td>\n",
       "      <td>[(i, sum(j) / len(j)) for i, j in list(d.items...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zip lists in python</td>\n",
       "      <td>13704860</td>\n",
       "      <td>zip two lists `[1, 2]` and `[3, 4]` into a lis...</td>\n",
       "      <td>zip([1, 2], [3, 4])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              intent  question_id  \\\n",
       "0  How to convert a list of multiple integers int...     41067960   \n",
       "1  How to convert a list of multiple integers int...     41067960   \n",
       "2  how to convert a datetime string back to datet...      4170655   \n",
       "3  Averaging the values in a dictionary based on ...     29565452   \n",
       "4                                zip lists in python     13704860   \n",
       "\n",
       "                                    rewritten_intent  \\\n",
       "0  Concatenate elements of a list 'x' of multiple...   \n",
       "1   convert a list of integers into a single integer   \n",
       "2  convert a DateTime string back to a DateTime o...   \n",
       "3  get the average of a list values for each key ...   \n",
       "4  zip two lists `[1, 2]` and `[3, 4]` into a lis...   \n",
       "\n",
       "                                             snippet  \n",
       "0    sum(d * 10 ** i for i, d in enumerate(x[::-1]))  \n",
       "1                      r = int(''.join(map(str, x)))  \n",
       "2  datetime.strptime('2010-11-13 10:33:54.227806'...  \n",
       "3  [(i, sum(j) / len(j)) for i, j in list(d.items...  \n",
       "4                                zip([1, 2], [3, 4])  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json(\"./data/conala-corpus/conala-train.json\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 532 ms, total: 15.7 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import itertools\n",
    "contents = Path(\"./data/conala-corpus/conala-mined.jsonl\").read_text()\n",
    "contents = contents.splitlines()\n",
    "df_mined = pd.DataFrame([dict(eval(x)) for x in contents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>intent</th>\n",
       "      <th>parent_answer_post_id</th>\n",
       "      <th>prob</th>\n",
       "      <th>question_id</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34705205_34705233_0</td>\n",
       "      <td>Sort a nested list by two elements</td>\n",
       "      <td>34705233</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>34705205</td>\n",
       "      <td>sorted(l, key=lambda x: (-int(x[1]), x[0]))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13905936_13905946_0</td>\n",
       "      <td>converting integer to list in python</td>\n",
       "      <td>13905946</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>13905936</td>\n",
       "      <td>[int(x) for x in str(num)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13837848_13838041_0</td>\n",
       "      <td>Converting byte string in unicode string</td>\n",
       "      <td>13838041</td>\n",
       "      <td>0.852143</td>\n",
       "      <td>13837848</td>\n",
       "      <td>c.decode('unicode_escape')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23490152_23490179_0</td>\n",
       "      <td>List of arguments with argparse</td>\n",
       "      <td>23490179</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>23490152</td>\n",
       "      <td>parser.add_argument('-t', dest='table', help='...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2721782_2721807_0</td>\n",
       "      <td>How to convert a Date string to a DateTime obj...</td>\n",
       "      <td>2721807</td>\n",
       "      <td>0.840372</td>\n",
       "      <td>2721782</td>\n",
       "      <td>datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                             intent  \\\n",
       "0  34705205_34705233_0                 Sort a nested list by two elements   \n",
       "1  13905936_13905946_0               converting integer to list in python   \n",
       "2  13837848_13838041_0           Converting byte string in unicode string   \n",
       "3  23490152_23490179_0                    List of arguments with argparse   \n",
       "4    2721782_2721807_0  How to convert a Date string to a DateTime obj...   \n",
       "\n",
       "   parent_answer_post_id      prob  question_id  \\\n",
       "0               34705233  0.869000     34705205   \n",
       "1               13905946  0.852670     13905936   \n",
       "2               13838041  0.852143     13837848   \n",
       "3               23490179  0.850829     23490152   \n",
       "4                2721807  0.840372      2721782   \n",
       "\n",
       "                                             snippet  \n",
       "0        sorted(l, key=lambda x: (-int(x[1]), x[0]))  \n",
       "1                         [int(x) for x in str(num)]  \n",
       "2                         c.decode('unicode_escape')  \n",
       "3  parser.add_argument('-t', dest='table', help='...  \n",
       "4  datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_snippet_pairs(row):\n",
    "    return (' '.join(tokenize_code(row.snippet)),\n",
    "            ' '.join(tokenize_docstring(\n",
    "                row.rewritten_intent if 'rewritten_intent' in row and row.rewritten_intent != None else row.intent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tokenize data and split into code and intent\"\"\"\n",
    "pairs = df_train.apply(get_intent_snippet_pairs, axis=\"columns\")\n",
    "pairs_mined = df_mined.apply(get_intent_snippet_pairs, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code, train_comment = zip(*pairs_mined.append(pairs))\n",
    "assert len(train_code) == len(train_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sorted', 'l', 'key', 'lambda', 'x', 'int', 'x', '1', 'x', '0']\n",
      "['utf-8', 'sorted', 'l', 'key', 'lambda', 'x', 'int', 'x', '1', 'x', '0', '']\n"
     ]
    }
   ],
   "source": [
    "from tokenize import tokenize\n",
    "from io import BytesIO\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "pytok = lambda s : [t.string for t in tokenize(BytesIO(s.encode('utf-8')).readline)]\n",
    "\n",
    "print(text_to_word_sequence(train_code[0]))\n",
    "print(pytok(train_code[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:Setting maximum document length to 15 based upon hueristic of 0.7 percentile.\n",
      " See full histogram by insepecting the `document_length_stats` attribute.\n",
      "WARNING:root:(1/2) done. 27 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 4 sec\n",
      "WARNING:root:Finished parsing 596,270 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 6 sec\n",
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:Setting maximum document length to 10 based upon hueristic of 0.7 percentile.\n",
      " See full histogram by insepecting the `document_length_stats` attribute.\n",
      "WARNING:root:(1/2) done. 20 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 5 sec\n",
      "WARNING:root:Finished parsing 596,270 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 5 sec\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Tokenize Code-Intent\"\"\"\n",
    "from ktext.preprocess import processor\n",
    "import logging\n",
    "   \n",
    "code_proc = processor(hueristic_pct_padding=.7, keep_n=20000)\n",
    "code_proc.set_tokenizer(tok)\n",
    "t_code = code_proc.fit_transform(train_code)\n",
    "\n",
    "comment_proc = processor(append_indicators=True, hueristic_pct_padding=.7, keep_n=14000, padding ='post')\n",
    "t_comment = comment_proc.fit_transform(train_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Saving processed files to disk\"\"\"\n",
    "import dill as dpickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_PATH = Path('./data/conala-corpus/pickle')\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the preprocessor\n",
    "with open(OUTPUT_PATH/'conala_code_proc.dpkl', 'wb') as f:\n",
    "    dpickle.dump(code_proc, f)\n",
    "\n",
    "with open(OUTPUT_PATH/'conala_comment_proc.dpkl', 'wb') as f:\n",
    "    dpickle.dump(comment_proc, f)\n",
    "\n",
    "# Save the processed data\n",
    "np.save(OUTPUT_PATH/'conala_t_code_vecs.npy', t_code)\n",
    "np.save(OUTPUT_PATH/'conala_t_comment_vecs.npy', t_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder input: (596270, 15)\n",
      "Shape of decoder input: (596270, 9)\n",
      "Shape of decoder target: (596270, 9)\n",
      "Size of vocabulary for data/conala-corpus/pickle/conala_code_proc.dpkl: 20,002\n",
      "Size of vocabulary for data/conala-corpus/pickle/conala_comment_proc.dpkl: 12,428\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from seq2seq_utils import load_decoder_inputs, load_encoder_inputs, load_text_processor\n",
    "\n",
    "\n",
    "encoder_input_data, encoder_seq_len = load_encoder_inputs(OUTPUT_PATH/'conala_t_code_vecs.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs(OUTPUT_PATH/'conala_t_comment_vecs.npy')\n",
    "num_encoder_tokens, enc_pp = load_text_processor(OUTPUT_PATH/'conala_code_proc.dpkl')\n",
    "num_decoder_tokens, dec_pp = load_text_processor(OUTPUT_PATH/'conala_comment_proc.dpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Word-Embedding (Embeddi (None, None, 800)    9942400     Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-1 (BatchNorma (None, None, 800)    3200        Decoder-Word-Embedding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Model (Model)           (None, 1000)         21407800    Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-GRU (GRU)               [(None, None, 1000), 5403000     Decoder-Batchnorm-1[0][0]        \n",
      "                                                                 Encoder-Model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-2 (BatchNorma (None, None, 1000)   4000        Decoder-GRU[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Final-Output-Dense (Dense)      (None, None, 12428)  12440428    Decoder-Batchnorm-2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 49,200,828\n",
      "Trainable params: 49,195,628\n",
      "Non-trainable params: 5,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_utils import build_seq2seq_model\n",
    "warmup_steps = 4000\n",
    "initial_lr = 2.0\n",
    "hidden_dim = 1000\n",
    "seq2seq_Model = build_seq2seq_model(word_emb_dim=800,\n",
    "                                    hidden_state_dim=hidden_dim,\n",
    "                                    encoder_seq_len=encoder_seq_len,\n",
    "                                    num_encoder_tokens=num_encoder_tokens,\n",
    "                                    num_decoder_tokens=num_decoder_tokens)\n",
    "seq2seq_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 524717 samples, validate on 71553 samples\n",
      "Epoch 1/16\n",
      "524717/524717 [==============================] - 257s 489us/step - loss: 3.5163 - val_loss: 3.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 3.0889 - val_loss: 3.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.9318 - val_loss: 3.5653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.8434 - val_loss: 3.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.7666 - val_loss: 3.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.6983 - val_loss: 3.3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.6488 - val_loss: 3.2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.6024 - val_loss: 3.2061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.5619 - val_loss: 3.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.5318 - val_loss: 3.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.5020 - val_loss: 3.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.4792 - val_loss: 3.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.4635 - val_loss: 3.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.4437 - val_loss: 3.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.4235 - val_loss: 3.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/16\n",
      "524717/524717 [==============================] - 249s 475us/step - loss: 2.4098 - val_loss: 3.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer Decoder-GRU was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder-Model_2/Encoder-Last-GRU/while/Exit_3:0' shape=(?, 1000) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "LOG_PATH = Path('./data/conala-corpus/logs')\n",
    "LOG_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "seq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.01), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "script_name_base = 'conala_func_'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(str(LOG_PATH/'{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base)),\n",
    "                                   save_best_only=True)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 16\n",
    "history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>question_id</th>\n",
       "      <th>rewritten_intent</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I send a signal from a python program?</td>\n",
       "      <td>15080500</td>\n",
       "      <td>send a signal `signal.SIGUSR1` to the current ...</td>\n",
       "      <td>os.kill(os.getpid(), signal.SIGUSR1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decode Hex String in Python 3</td>\n",
       "      <td>3283984</td>\n",
       "      <td>decode a hex string '4a4b4c' to UTF-8.</td>\n",
       "      <td>bytes.fromhex('4a4b4c').decode('utf-8')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>check if all elements in a list are identical</td>\n",
       "      <td>3844801</td>\n",
       "      <td>check if all elements in list `myList` are ide...</td>\n",
       "      <td>all(x == myList[0] for x in myList)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Format string dynamically</td>\n",
       "      <td>4302166</td>\n",
       "      <td>format number of spaces between strings `Pytho...</td>\n",
       "      <td>print('%*s : %*s' % (20, 'Python', 20, 'Very G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to convert a string from CP-1251 to UTF-8?</td>\n",
       "      <td>7555335</td>\n",
       "      <td>None</td>\n",
       "      <td>d.decode('cp1251').encode('utf8')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           intent  question_id  \\\n",
       "0  How can I send a signal from a python program?     15080500   \n",
       "1                   Decode Hex String in Python 3      3283984   \n",
       "2   check if all elements in a list are identical      3844801   \n",
       "3                       Format string dynamically      4302166   \n",
       "4  How to convert a string from CP-1251 to UTF-8?      7555335   \n",
       "\n",
       "                                    rewritten_intent  \\\n",
       "0  send a signal `signal.SIGUSR1` to the current ...   \n",
       "1             decode a hex string '4a4b4c' to UTF-8.   \n",
       "2  check if all elements in list `myList` are ide...   \n",
       "3  format number of spaces between strings `Pytho...   \n",
       "4                                               None   \n",
       "\n",
       "                                             snippet  \n",
       "0               os.kill(os.getpid(), signal.SIGUSR1)  \n",
       "1            bytes.fromhex('4a4b4c').decode('utf-8')  \n",
       "2                all(x == myList[0] for x in myList)  \n",
       "3  print('%*s : %*s' % (20, 'Python', 20, 'Very G...  \n",
       "4                  d.decode('cp1251').encode('utf8')  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json(\"./data/conala-corpus/conala-test.json\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 159 =================\n",
      "\n",
      "Original Input:\n",
      " x 1 for x in b \n",
      "\n",
      "Original Output:\n",
      " get reverse of list items from list ' b ' using extended slicing\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert a list of tuples into a list\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 222 =================\n",
      "\n",
      "Original Input:\n",
      " int \n",
      "\n",
      "Original Output:\n",
      " function to convert strings into integers\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert a list of tuples into a list\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 146 =================\n",
      "\n",
      "Original Input:\n",
      " os chdir owd \n",
      "\n",
      "Original Output:\n",
      " change working directory to the directory ` owd `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to get the current directory info hash in python\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 430 =================\n",
      "\n",
      "Original Input:\n",
      " for i in range 256 for j in range 256 ip 192 168 d d i j print ip \n",
      "\n",
      "Original Output:\n",
      " loop through the ip address range \" 192.168.x.x \"\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to use a list of dictionaries as a table\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 422 =================\n",
      "\n",
      "Original Input:\n",
      " nums int x for x in intstringlist \n",
      "\n",
      "Original Output:\n",
      " converting list of strings ` intstringlist ` to list of integer ` nums `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert a list of tuples into a list\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 434 =================\n",
      "\n",
      "Original Input:\n",
      " target write r n r n r n line1 line2 line3 \n",
      "\n",
      "Original Output:\n",
      " write multiple strings ` line1 ` , ` line2 ` and ` line3 ` in one line in a file ` target `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to write a polling function that returns a string\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 97 =================\n",
      "\n",
      "Original Input:\n",
      " datetime datetime strptime string_date Y m d H M S f \n",
      "\n",
      "Original Output:\n",
      " convert a string into datetime using the format ' % y-%m-%d % h:%m:%s.%f '\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert gmt time to est time\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 430 =================\n",
      "\n",
      "Original Input:\n",
      " for i in range 256 for j in range 256 ip 192 168 d d i j print ip \n",
      "\n",
      "Original Output:\n",
      " loop through the ip address range \" 192.168.x.x \"\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to use a list of dictionaries as a table\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 373 =================\n",
      "\n",
      "Original Input:\n",
      " a decode string_escape \n",
      "\n",
      "Original Output:\n",
      " remove escape character from string \" \\\\a \"\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert a string to a list of strings\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 480 =================\n",
      "\n",
      "Original Input:\n",
      " f open myfile w f write hi there n f close \n",
      "\n",
      "Original Output:\n",
      " write line \" hi there \" to file ` myfile `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to read a file from a gzip file with\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 324 =================\n",
      "\n",
      "Original Input:\n",
      " dict Name Joe Age 22 \n",
      "\n",
      "Original Output:\n",
      " convert list ` [ ( ' name ' , ' joe ' ) , ( ' age ' , 22 ) ] ` into a dictionary\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert a list of tuples into a dict\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 462 =================\n",
      "\n",
      "Original Input:\n",
      " join trans category \n",
      "\n",
      "Original Output:\n",
      " join together with \" , \" elements inside a list indexed with ' category ' within a dictionary ` trans `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to use a function to execute a function in\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 122 =================\n",
      "\n",
      "Original Input:\n",
      " l count a \n",
      "\n",
      "Original Output:\n",
      " count the occurrences of item \" a \" in list ` l `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to get all the hyponyms of a list of\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 98 =================\n",
      "\n",
      "Original Input:\n",
      " index for index item in enumerate thelist if item 0 332 \n",
      "\n",
      "Original Output:\n",
      " find the index of a list with the first element equal to ' 332 ' within the list of lists ` thelist `\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to get the index of a list of all\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 466 =================\n",
      "\n",
      "Original Input:\n",
      " Entry objects filter pub_date__contains 08 00 \n",
      "\n",
      "Original Output:\n",
      " django filter by hour\n",
      "\n",
      "****** Predicted Output ******:\n",
      " how to convert a list of objects into a list\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_utils import Seq2Seq_Inference\n",
    "import pandas as pd\n",
    "\n",
    "pairs = df_test.apply(get_intent_snippet_pairs, axis=\"columns\")\n",
    "test_code, test_comment = zip(*pairs)\n",
    "\n",
    "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=enc_pp,\n",
    "                                 decoder_preprocessor=dec_pp,\n",
    "                                 seq2seq_model=seq2seq_Model)\n",
    "\n",
    "demo_testdf = pd.DataFrame({'code':test_code, 'comment':test_comment, 'ref':''})\n",
    "seq2seq_inf.demo_model_predictions(n=15, df=demo_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Generating predictions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191e0823c3164393a58a6380a1c2231b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Calculating BLEU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02662236674559463"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_inf.evaluate_model(input_strings=test_code, \n",
    "                           output_strings=test_comment, \n",
    "                           max_len=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_utils import create_token_map, build_vocab, build_data\n",
    "\n",
    "TRANS_PATH = Path('./data/transformer/')\n",
    "\n",
    "tr_src_tokens = build_vocab(create_token_map(train_code), outpath=TRANS_PATH/\"train_code_tokens.txt\")\n",
    "tr_target_tokens = build_vocab(create_token_map(train_comment), outpath=TRANS_PATH/\"train_comment_tokens.txt\")\n",
    "\n",
    "tst_src_tokens = build_vocab(create_token_map(test_code), outpath=TRANS_PATH/\"test_code_tokens.txt\")\n",
    "tst_target_tokens = build_vocab(create_token_map(test_comment), outpath=TRANS_PATH/\"test_comment_tokens.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_data(source_data=train_code, target_data=train_comment, \n",
    "                              src_tokens=tr_src_tokens, tar_tokens=tr_target_tokens)\n",
    "X_test, y_test = build_data(source_data=test_code, target_data=test_comment, \n",
    "                              src_tokens=tst_src_tokens, tar_tokens=tst_target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, None)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, None)         0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, None)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, None, 256)    3176704     lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, None, 256)    17920       lambda_61[0][0]                  \n",
      "                                                                 lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, None, 256)    15549440    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 256)    0           embedding_27[0][0]               \n",
      "                                                                 embedding_26[0][0]               \n",
      "                                                                 embedding_28[0][0]               \n",
      "                                                                 embedding_26[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, None, 256)    0           lambda_1[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_201 (Dense)               (None, None, 256)    65536       dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_202 (Dense)               (None, None, 256)    65536       dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, None)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, None, None)   0           dense_201[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, None, None)   0           dense_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, None)         0           lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, None, None)   0           lambda_64[0][0]                  \n",
      "                                                                 lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, None)         0           lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None)   0           lambda_68[0][0]                  \n",
      "                                                                 lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_203 (Dense)               (None, None, 256)    65536       dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, None, None)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, None, None)   0           dense_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, None, None)   0           dropout_97[0][0]                 \n",
      "                                                                 lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, None, 256)    0           lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, None, 256)    65792       lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, None, 256)    0           time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, 256)    0           dropout_107[0][0]                \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_81 (LayerNo (None, None, 256)    512         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, None, 512)    131584      layer_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, None, 256)    131328      conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, None, 256)    0           conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, 256)    0           dropout_98[0][0]                 \n",
      "                                                                 layer_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_82 (LayerNo (None, None, 256)    512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_205 (Dense)               (None, None, 256)    65536       layer_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_206 (Dense)               (None, None, 256)    65536       layer_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, None, None)   0           dense_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, None, None)   0           dense_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, None)         0           lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, None, None)   0           lambda_72[0][0]                  \n",
      "                                                                 lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, None)         0           lambda_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None)   0           lambda_76[0][0]                  \n",
      "                                                                 lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, None, None)   0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, None, None)   0           lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_207 (Dense)               (None, None, 256)    65536       layer_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_209 (Dense)               (None, None, 256)    65536       lambda_1[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_210 (Dense)               (None, None, 256)    65536       lambda_1[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, None, None)   0           lambda_80[0][0]                  \n",
      "                                                                 lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, None, None)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, None, None)   0           dense_207[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, None, None)   0           dense_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, None, None)   0           dense_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, None, None)   0           lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, None, None)   0           dropout_99[0][0]                 \n",
      "                                                                 lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, None, None)   0           lambda_84[0][0]                  \n",
      "                                                                 lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, None, None)   0           lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, None, 256)    0           lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None)   0           lambda_88[0][0]                  \n",
      "                                                                 lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, None, 256)    65792       lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None)   0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_211 (Dense)               (None, None, 256)    65536       lambda_1[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, None, 256)    0           time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, None, None)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, None, None)   0           dense_211[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, 256)    0           dropout_108[0][0]                \n",
      "                                                                 layer_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, None, None)   0           dropout_101[0][0]                \n",
      "                                                                 lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_83 (LayerNo (None, None, 256)    512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, None, 256)    0           lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, None, 512)    131584      layer_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, None, 256)    65792       lambda_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, None, 256)    131328      conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, None, 256)    0           time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, None, 256)    0           conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, 256)    0           dropout_109[0][0]                \n",
      "                                                                 lambda_1[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, 256)    0           dropout_100[0][0]                \n",
      "                                                                 layer_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_85 (LayerNo (None, None, 256)    512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_84 (LayerNo (None, None, 256)    512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_213 (Dense)               (None, None, 256)    65536       layer_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_214 (Dense)               (None, None, 256)    65536       layer_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, None, None)   0           lambda_59[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, None, None)   0           dense_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, None, None)   0           dense_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, None, None)   0           lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, None, None)   0           lambda_92[0][0]                  \n",
      "                                                                 lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, None, None)   0           lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None)   0           lambda_96[0][0]                  \n",
      "                                                                 lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_215 (Dense)               (None, None, 256)    65536       layer_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, None, None)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, None, None)   0           dense_215[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, None, None)   0           dropout_102[0][0]                \n",
      "                                                                 lambda_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, None, 256)    0           lambda_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, None, 256)    65792       lambda_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, None, 256)    0           time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, 256)    0           dropout_110[0][0]                \n",
      "                                                                 layer_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_86 (LayerNo (None, None, 256)    512         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, None, 512)    131584      layer_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, None, 256)    131328      conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, None, 256)    0           conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, 256)    0           dropout_103[0][0]                \n",
      "                                                                 layer_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_87 (LayerNo (None, None, 256)    512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_217 (Dense)               (None, None, 256)    65536       layer_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, None, 256)    65536       layer_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, None, None)   0           dense_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, None, None)   0           dense_218[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, None, None)   0           lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, None, None)   0           lambda_100[0][0]                 \n",
      "                                                                 lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, None, None)   0           lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None)   0           lambda_104[0][0]                 \n",
      "                                                                 lambda_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_219 (Dense)               (None, None, 256)    65536       layer_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, None, None)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, None, None)   0           dense_219[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, None, None)   0           dropout_104[0][0]                \n",
      "                                                                 lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, None, 256)    0           lambda_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistri (None, None, 256)    65792       lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, None, 256)    0           time_distributed_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, 256)    0           dropout_111[0][0]                \n",
      "                                                                 layer_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_88 (LayerNo (None, None, 256)    512         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_221 (Dense)               (None, None, 256)    65536       layer_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_222 (Dense)               (None, None, 256)    65536       layer_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, None, None)   0           dense_221[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, None, None)   0           dense_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, None, None)   0           lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, None, None)   0           lambda_108[0][0]                 \n",
      "                                                                 lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, None, None)   0           lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None)   0           lambda_112[0][0]                 \n",
      "                                                                 lambda_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_223 (Dense)               (None, None, 256)    65536       layer_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, None, None)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, None, None)   0           dense_223[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, None, None)   0           dropout_105[0][0]                \n",
      "                                                                 lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, None, 256)    0           lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistri (None, None, 256)    65792       lambda_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, None, 256)    0           time_distributed_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, 256)    0           dropout_112[0][0]                \n",
      "                                                                 layer_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_89 (LayerNo (None, None, 256)    512         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, None, 512)    131584      layer_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, None, 256)    131328      conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, None, 256)    0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, 256)    0           dropout_106[0][0]                \n",
      "                                                                 layer_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_90 (LayerNo (None, None, 256)    512         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, None, 12409)  3176704     layer_normalization_90[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 24,551,936\n",
      "Trainable params: 24,534,016\n",
      "Non-trainable params: 17,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformer_models.keras_trans.transformer import Transformer, LRSchedulerPerStep\n",
    "from keras.optimizers import Adam\n",
    "hidden_dim = 256\n",
    "s2s = Transformer(tr_src_tokens, tr_target_tokens, len_limit=70, d_model=hidden_dim, d_inner_hid=512, \\\n",
    "    n_head=8, layers=2, dropout=0.1)\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger('./data/logs/trans.log')\n",
    "\n",
    "mfile = './models/trans.model.h5'\n",
    "lr_scheduler = LRSchedulerPerStep(hidden_dim, 4000) \n",
    "model_saver = ModelCheckpoint(mfile, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "s2s.compile(Adam(0.001, 0.9, 0.98, epsilon=1e-9))\n",
    "s2s.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5405983 samples, validate on 737180 samples\n",
      "Epoch 1/16\n",
      " 422656/5405983 [=>............................] - ETA: 2:41:08 - loss: 3.0299 - ppl: 610.8049 - accu: 0.3922"
     ]
    }
   ],
   "source": [
    "s2s.model.fit([X_train, y_train], batch_size=batch_size, epochs=epochs,\n",
    "              validation_split=0.12,\n",
    "              callbacks=[lr_scheduler, model_saver, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
